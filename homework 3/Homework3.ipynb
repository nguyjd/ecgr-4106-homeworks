{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f9a9d1",
   "metadata": {},
   "source": [
    "Jonathon Nguyen\n",
    "\n",
    "ID: 801093003\n",
    "\n",
    "Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef050df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535e0e2",
   "metadata": {},
   "source": [
    "<b>Problem 1a</b>  \n",
    "Build a Convolutional Neural Network, like what we built in lectures (without skip connections), to classify the images across all 10 classes in CIFAR 10. \n",
    "\n",
    "You need to adjust the fully connected layer at the end properly with respect to the number of output classes. Train your network for 300 epochs. \n",
    "\n",
    "Report your training time, training loss, and evaluation accuracy after 300 epochs. Analyze your results in your report and compare them against a fully connected network (homework 2) on training time, achieved accuracy, and model size. Make sure to submit your code by providing the GitHub URL of your course repository for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a21195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels1 = 32):\n",
    "        super().__init__()\n",
    "        self.n_channels1 = n_channels1\n",
    "        self.conv1 = nn.Conv2d(3, self.n_channels1, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(n_channels1, (self.n_channels1 // 2), kernel_size = 3, padding = 1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * (self.n_channels1 // 2), 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = f.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = f.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * (self.n_channels1 // 2))\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, optimizer, model, loss_fn, train_loader, val_loader):\n",
    "    training_losses = []\n",
    "    val_losses = []\n",
    "    accuracies = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Temp vars for use in finding the accuracy.\n",
    "        correct_labels = 0\n",
    "        count = 0\n",
    "        loss_val_value = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                # Move the data to correct device\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                \n",
    "                # Pass imgs through the model and find the loss.\n",
    "                output = model(imgs)\n",
    "                loss_val = loss_fn(output, labels)\n",
    "                loss_val_value += float(loss_val)\n",
    "                \n",
    "                # Find the accurcey of the model.\n",
    "                _, predicted = torch.max(output, dim=1)\n",
    "                count += labels.shape[0]\n",
    "                correct_labels += int((predicted == labels).sum())\n",
    "            \n",
    "            # Store the loss and accuracy.\n",
    "            loss_val_value /= len(val_loader)\n",
    "            val_losses.append(loss_val_value)\n",
    "            accuracies.append(correct_labels/count)\n",
    "        \n",
    "        loss_train_value = 0\n",
    "        for imgs, labels in train_loader:\n",
    "            # Move the data to correct device\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            # Pass imgs through the model and find the loss.\n",
    "            output = model(imgs)\n",
    "            loss_train = loss_fn(output, labels)\n",
    "            loss_train_value += float(loss_train)\n",
    "            \n",
    "            # Adject the params\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Store the loss\n",
    "        loss_train_value /= len(train_loader)\n",
    "        training_losses.append(loss_train_value)\n",
    "        \n",
    "        # Print out the loss every 10 epoch\n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            print(f\"Epoch: {epoch}, Training Loss: {loss_train_value}\", end=\"\")\n",
    "            print(f\", Validation Loss: {loss_val_value}, Accuracy: {(correct_labels/count)*100}%\")\n",
    "        \n",
    "    return training_losses, val_losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372047cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                         (0.2470, 0.2435, 0.2616))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the cifar10 dataset.\n",
    "data = '.\\cifar10'\n",
    "cirfar10_train = datasets.CIFAR10(data, train=True, download=True, transform=transforms)\n",
    "cirfar10_val = datasets.CIFAR10(data, train=False, download=True, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73711c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print(f\"Training on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73622bc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-2\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "model = CNN().to(device=device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Load the data into a dataloaders.\n",
    "train_loader = torch.utils.data.DataLoader(cirfar10_train, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True, \n",
    "                                           persistent_workers=True, \n",
    "                                           num_workers=6)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(cirfar10_val, \n",
    "                                         batch_size=BATCH_SIZE, \n",
    "                                         shuffle=False, \n",
    "                                         pin_memory=True, \n",
    "                                         persistent_workers=True, \n",
    "                                         num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using time to time the training.\n",
    "start_time = time.time()\n",
    "training_losses, val_losses, accuracies = training_loop(NUM_EPOCHS, optimizer, model, loss, train_loader, val_loader)\n",
    "end_time = time.time()\n",
    "\n",
    "# Close the threads\n",
    "train_loader._iterator._shutdown_workers()\n",
    "val_loader._iterator._shutdown_workers()\n",
    "\n",
    "# Report the final stats about the training.\n",
    "print(\" \")\n",
    "print(f\"Final Loss: {training_losses[-1]}, Final Accuracy: {accuracies[-1] * 100}%\")\n",
    "print(f\"Training Time: {(end_time - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b034cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Losses\n",
    "\n",
    "fig = plt.figure()\n",
    "# Name the x and y axis\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Plot the model and the actual values.\n",
    "plt.plot(training_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583245f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy of the model.\n",
    "\n",
    "fig = plt.figure()\n",
    "# Name the x and y axis\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Percents\")\n",
    "\n",
    "for i, x in enumerate(accuracies):\n",
    "    accuracies[i] = x * 100\n",
    "    \n",
    "\n",
    "plt.plot(accuracies, label='Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea1830",
   "metadata": {},
   "source": [
    "<b>Problem 1b</b>  \n",
    "Extend your CNN by adding one more additional convolution layer followed by an activation function and pooling function. \n",
    "\n",
    "You also need to adjust your fully connected layer properly with respect to intermediate feature dimensions. \n",
    "\n",
    "Train your network for 300 epochs. Report your training time, loss, and evaluation accuracy after 300 epochs. Analyze your results in your report and compare your model size and accuracy over the baseline implementation in Problem1a. Do you see any over-fitting? Make sure to submit your code by providing the GitHub URL of your course repository for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7df7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self, n_channels1 = 32):\n",
    "        super().__init__()\n",
    "        self.n_channels1 = n_channels1\n",
    "        self.conv1 = nn.Conv2d(3, self.n_channels1, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(n_channels1, (self.n_channels1 // 2), kernel_size = 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d((self.n_channels1 // 2), (self.n_channels1 // 4), kernel_size = 3, padding = 1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * (self.n_channels1 // 4), 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = f.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = f.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = f.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * (self.n_channels1 // 4))\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2098a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-2\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "model = CNN2().to(device=device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Load the data into a dataloaders.\n",
    "train_loader = torch.utils.data.DataLoader(cirfar10_train, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True, \n",
    "                                           persistent_workers=True, \n",
    "                                           num_workers=6)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(cirfar10_val, \n",
    "                                         batch_size=BATCH_SIZE, \n",
    "                                         shuffle=False, \n",
    "                                         pin_memory=True, \n",
    "                                         persistent_workers=True, \n",
    "                                         num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using time to time the training.\n",
    "start_time = time.time()\n",
    "training_losses, val_losses, accuracies = training_loop(NUM_EPOCHS, optimizer, model, loss, train_loader, val_loader)\n",
    "end_time = time.time()\n",
    "\n",
    "# Close the threads\n",
    "train_loader._iterator._shutdown_workers()\n",
    "val_loader._iterator._shutdown_workers()\n",
    "\n",
    "# Report the final stats about the training.\n",
    "print(\" \")\n",
    "print(f\"Final Loss: {training_losses[-1]}, Final Accuracy: {accuracies[-1] * 100}%\")\n",
    "print(f\"Training Time: {(end_time - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00061247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Losses\n",
    "\n",
    "fig = plt.figure()\n",
    "# Name the x and y axis\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Plot the model and the actual values.\n",
    "plt.plot(training_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47443ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy of the model.\n",
    "\n",
    "fig = plt.figure()\n",
    "# Name the x and y axis\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Percents\")\n",
    "\n",
    "for i, x in enumerate(accuracies):\n",
    "    accuracies[i] = x * 100\n",
    "    \n",
    "\n",
    "plt.plot(accuracies, label='Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f70eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "model_p1a = CNN()\n",
    "model_p1b = CNN2()\n",
    "\n",
    "macs, params = get_model_complexity_info(model_p1a, (3, 32, 32), as_strings=True,\n",
    " print_per_layer_stat=False, verbose=False)\n",
    "# print out the computational cost and the Model size.\n",
    "print(\"Problem 1 Part a\")\n",
    "print(\"Model size: \" + params)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "macs, params = get_model_complexity_info(model_p1b, (3, 32, 32), as_strings=True,\n",
    " print_per_layer_stat=False, verbose=False)\n",
    "# print out the computational cost and the Model size.\n",
    "print(\"Problem 1 Part b\")\n",
    "print(\"Model size: \" + params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4333f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
